
\chapter{Conclusions and Further Work}

\section{Conclusions}

In this thesis, I have presented a thorough analysis of deep learning in automatic chord recognition. There are a few key takeaways.

ACR models are not complex. Good performance relative to state-of-the-art can be achieved with few parameters. It is likely that the task of determining which pitch classes are present from a CQT is a relatively simple operation for a neural network to learn. Performance does not increase with model size past a low threshold. Without smoothing, frame-wise predictions result in too many chord transitions. Of the smoothing methods tested, fixed transition penalties or transition matrices are preferred. Weighting the loss function allows control over performance on rare qualities but requires sacrificing overall accuracy. Introducing structured representations of chords as additional targets provides a small performance gain. Features extracted from MusicGen contain information relevant to ACR but not any more than is already contained in the CQT.

There are a number of explanations for the low ceiling on performance and the gap between \texttt{mirex} score and accuracy. First is that annotations are too ambiguous or inconsistent for classifiers to learn the upper extensions of chords. Further research on inter-annotator agreement on this dataset is required to assess whether or not this is the case. Second is that there are too few instances of rare chord classes. This leads to the current models failing to learn signals indicating the presence of such classes. Fourth is that the current models are unable to use information from a wider context to discern chord qualities. Different genres or different repetitions of the same chord within a song may give further clues of the musically coherent chord quality.

Pitch augmentation works well to encourage root-invariance and improve accuracy. The use of synthetic data provides an exciting avenue for future research. Results presented here show signs that with newer models and more careful construction, synthetic data could provide many new training examples with a customisable chord distribution.

Predicting chords over beats instead of frames improves the interpretation of the model's outputs while performance is unaffected. Predicting chords over the true chord intervals results in the highest \texttt{mirex} score seen in the literature suggesting that there remains room for improvement in the way chord transitions are detected.

While deep learning models are powerful chord recognisers, there is still much work to be done before the problem is solved. The `glass ceiling' is yet to be broken but the work presented here provides a solid foundation for future research and hope that the true ceiling is much higher.

\section{Future Work}

Many of the experiments conducted would benefit from further analysis. Implementing a sampling method which prioritises rare qualities may yield improved results over a weighted loss function. Looking at alternative methods of structuring chords beyond the pitch classes present may improve results, like the work of \citet{ACRLargeVocab1}.  The use of larger generative models trained on a wider variety of data may improve the richness of its representations and its utility as a feature extractor for ACR.

Work presented here highlights also suggests new avenues of research.

\textbf{Multiple Data Sources.} Results on synthetic data show enough promise to continue this direction of research which I intend to pursue. A more closely controlled chord sequence generation process may help. For example, one could construct examples designed to highlight the difference between different seventh qualities and look at the difference in recall on seventh qualities to see if they improve. Other datasets also exist such as \emph{HookTheory}. I was not able to obtain audio from this source. However, results here also suggest that gathering more data from the same distribution may not lead to improvements. A better source of data may be \emph{JAAH} which would enable comparisons across genres and chord distributions.

\textbf{Finding better chord transitions than beats.} The high \texttt{mirex} score found in Section~\ref{sec:beat-synchronisation} suggests two things. First, targeting the problem of identifying chord transitions rather than beats may yield better results. \citet{ChorusAlignmentJAAH} jointly estimate beats and chords but to the best of my knowledge, no modern work has jointly estimated chord transitions and chord symbols. Second, current models are missing information regarding presence of pitch classes that is present in the CQT. Perhaps this information is spread out in time or obscured by nearby frames that are irrelevant to the current chord. Understanding this effect may lead to new insights.

\textbf{Subjective annotations.} Inter-annotator agreement of the root of a chord is estimated at lying between 76\%~\citep{AnnotatorAgreement76} and 94\%~\citep{RockHarmonyAnalysis94} but these metrics are calculated using only four and two annotators respectively. \citet{FourTimelyInsights} and \citet{UnderstandingSubjectivity} posit that agreement between annotations can be far lower than that for some songs. Analysis of such an effect on commonly used datasets would provide a valuable contribution to the field. Such analysis could be used to inform the design of more subtle chord annotations which take into account multiple annotations and degrees of uncertainty.

A statement regarding the limitations of the conclusions presented here and ethics of musical machine learning models can be found in Appendix~\ref{app:limitations_and_ethics}.

 