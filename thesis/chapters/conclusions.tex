
\chapter{Conclusions and Further Work}

\section{Conclusions}

In this thesis, I have presented a thorough analysis of deep learning in automatic chord recognition. There are a few key takeaways.

ACR models are not complex. Good performance relative to state-of-the-art can be achieved with few parameters. It is likely that the task of determining which pitch classes are present from a CQT is a relatively simple operation for a neural network to learn. Performance does not increase with model size past a low threshold. Without smoothing, frame-wise predictions result in too many chord transitions. Of the smoothing methods tested, fixed transition penalties or transition matrices are preferred. Weighting the loss function allows control over performance on rare qualities, but requires sacrificing a little overall accuracy. Introducing structured representations of chords as additional targets provides a small performance gain. Features extracted from MusicGen contain information relevant to ACR but not any more than is already contained in the CQT.

Pitch augmentation works well to encourage root-invariance and improve accuracy. The use of synthetic data provides an exciting avenue for future research. Results presented here are based on preliminary experiments but do show signs that with newer models and more careful construction, synthetic data could provide many new training examples with a customisable chord distribution.

Predicting chords over beats instead of frames does affect performance while improving the interpretation of the model's outputs. Predicting chords over the true chord intervals results in the highest \texttt{mirex} score seen in the literature suggesting that there remains room for improvement in the way chord transitions are detected.

While deep learning models are powerful chord recognisers, there is still much work to be done before the problem is solved. The `glass ceiling' is yet to be broken but the work presented here provides a solid foundation for future research and hope that the true ceiling is much higher.

\section{Future Work}

Many of the experiments conducted would benefit from further analysis. Implementing a sampling method which prioritises rare qualities may yield improved results over a weighted loss function. Looking at alternative methods of structuring chords beyond simply the pitch classes present may improve results, like the work of \citet{ACRLargeVocab1}.  The use of larger generative models trained on a wider variety of data may improve the richness of its representations. 

Work presented here highlights also suggests new avenues of research.

\textbf{Multiple Data Sources.} Results on synthetic data show enough promise to continue. A more closely controlled chord sequence generation process may help. For example, constructing examples specifically to highlight the differences between different sevenths and observing the model's recall on sevenths. Other datasets also exist such as \emph{HookTheory}. I was not able to obtain audio from this source. However, results here also suggest that gathering more data from the same distribution may not lead to improvements. A better source of data may be \emph{JAAH} which would enable comparisons across genres and chord distributions.

\textbf{Finding better chord transitions than beats.} The high \texttt{mirex} score found in Section~\ref{sec:beat-synchronisation} suggests two things. First, targeting the problem of identifying chord transitions rather than beats may yield better results. \citet{ChorusAlignmentJAAH} jointly estimate beats and chords but to the best of my knowledge, no modern work has jointly estimated chord transitions and chord. Second, current models are missing information regarding presence of pitch classes that is present in the CQT. Perhaps this information is spread out in time or obscured by nearby frames that are irrelevant to the current chord. Understanding this effect may lead to new insights.

\textbf{Subjective annotations.} Inter-annotator agreement of the root of a chord is estimated at lying between 76\%~\citep{AnnotatorAgreement76} and 94\%~\citep{RockHarmonyAnalysis94} but these metrics are calculated using only four and two annotators respectively. \citet{FourTimelyInsights} and \citet{UnderstandingSubjectivity} posit that agreement between annotations can be far lower than that for some songs. Analysis of such an effect on commonly used datasets would provide a valuable contribution to the field. Such analysis could be used to inform the design of more subtle chord annotations which take into account multiple annotations and degrees of uncertainty.

A statement on the limitations of the conclusions presented and ethics of musical machine learning models can be found in Appendix~\ref{app:limitations_and_ethics}.

 